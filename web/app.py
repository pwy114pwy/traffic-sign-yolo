# web/app.py
import os
import cv2
import torch
import time
from flask import Flask, request, render_template, jsonify
from pathlib import Path
import sys
import dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# æ·»åŠ  yolov5 åˆ°ç³»ç»Ÿè·¯å¾„
FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # é¡¹ç›®æ ¹ç›®å½• (traffic-sign-yolo)
YOLOV5_ROOT = ROOT / 'yolov5'
sys.path.append(str(YOLOV5_ROOT))

from models.experimental import attempt_load
from utils.general import non_max_suppression, scale_boxes
from utils.plots import Annotator, colors
from utils.augmentations import letterbox

# ======================
# é…ç½®åŒº
# ======================
# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
PROJECT_ROOT = os.getenv("PROJECT_ROOT", str(ROOT))
WEIGHTS_PATH = os.getenv("WEIGHTS_PATH", 
                       os.path.join(PROJECT_ROOT, "yolov5", "runs", "train", "exp3", "weights", "best.pt"))
UPLOAD_FOLDER = os.getenv("UPLOAD_FOLDER", 
                         os.path.join(PROJECT_ROOT, "web", "static", "uploads"))
RESULT_FOLDER = os.getenv("RESULT_FOLDER", 
                         os.path.join(PROJECT_ROOT, "web", "static", "results"))

# åˆ›å»ºæ–‡ä»¶å¤¹
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)

# æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
print(f"ğŸ“ PROJECT_ROOT: {PROJECT_ROOT}")
print(f"ğŸ“¦ WEIGHTS_PATH: {WEIGHTS_PATH}")
print(f"ğŸ“¤ UPLOAD_FOLDER: {UPLOAD_FOLDER}")
print(f"ğŸ“¥ RESULT_FOLDER: {RESULT_FOLDER}")

# å…¨å±€åŠ è½½æ¨¡å‹ï¼ˆå¯åŠ¨æ—¶åªåŠ è½½ä¸€æ¬¡ï¼‰
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Loading model from: {WEIGHTS_PATH}")
model = attempt_load(WEIGHTS_PATH, device=DEVICE)
stride = int(model.stride.max())  # è·å–æ¨¡å‹æ­¥é•¿
names = model.module.names if hasattr(model, 'module') else model.names
print(f"Model loaded. Classes: {len(names)}")

app = Flask(__name__)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    file = request.files['image']
    if not file or not file.filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        return "è¯·ä¸Šä¼ æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ï¼", 400

    # è·å–æ£€æµ‹å‚æ•°
    conf_thres = float(request.form.get('conf_thres', 0.25))
    iou_thres = float(request.form.get('iou_thres', 0.45))

    # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
    input_path = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(input_path)

    # è¯»å–åŸå›¾
    img0 = cv2.imread(input_path)
    if img0 is None:
        return "æ— æ³•è¯»å–å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ ¼å¼ï¼", 400

    # å¼€å§‹è®¡æ—¶
    start_time = time.time()

    # ä½¿ç”¨letterboxé¢„å¤„ç†ï¼Œä¿æŒå®½é«˜æ¯”
    img = letterbox(img0, 640, stride=stride)[0]  # ä½¿ç”¨æ¨¡å‹çš„stride
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
    img = torch.from_numpy(img.copy()).to(DEVICE).float() / 255.0
    img = img.unsqueeze(0)

    # æ¨ç†
    with torch.no_grad():
        pred = model(img, augment=True)[0]  # å¯ç”¨augmentè¿›è¡Œå¤šå°ºåº¦æµ‹è¯•
        pred = non_max_suppression(pred, conf_thres=conf_thres, iou_thres=iou_thres)  # é™ä½é˜ˆå€¼

    # è®¡ç®—æ¨ç†æ—¶é—´
    inference_time = time.time() - start_time

    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦è¿‡å°ï¼Œå¦‚æœæ˜¯åˆ™æ”¾å¤§
    original_shape = img0.shape
    min_dim = min(original_shape[0], original_shape[1])
    SCALE_THRESHOLD = 200  # æœ€å°å°ºå¯¸é˜ˆå€¼ï¼Œæé«˜åˆ°200åƒç´ ä»¥ç¡®ä¿æ ‡ç­¾æœ‰è¶³å¤Ÿç©ºé—´
    scale_factor = 1.0
    
    if min_dim < SCALE_THRESHOLD:
        # è®¡ç®—æ”¾å¤§æ¯”ä¾‹
        scale_factor = SCALE_THRESHOLD / min_dim
        new_width = int(original_shape[1] * scale_factor)
        new_height = int(original_shape[0] * scale_factor)
        img0 = cv2.resize(img0, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
    
    # åŠ¨æ€è®¡ç®—çº¿æ¡å®½åº¦ï¼Œæ ¹æ®å›¾ç‰‡å¤§å°è°ƒæ•´
    min_dim = min(img0.shape[0], img0.shape[1])
    line_width = max(1, int(min_dim / 300))  # æ¯300åƒç´ å¯¹åº”1ä¸ªåƒç´ å®½åº¦ï¼Œæœ€å°ä¸º1
    line_width = min(line_width, 4)  # æœ€å¤§å®½åº¦ä¸º4
    
    # ç”»æ£€æµ‹æ¡†
    annotator = Annotator(img0, line_width=line_width, example=str(names))
    
    # å¼‚å¸¸æ£€æµ‹è®¾ç½®ï¼šç½®ä¿¡åº¦é˜ˆå€¼
    ANOMALY_CONF_THRES = 0.5  # ä½äºæ­¤é˜ˆå€¼çš„æ£€æµ‹ç»“æœè§†ä¸ºå¼‚å¸¸
    
    # æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
    detection_count = 0
    unique_classes = set()
    total_confidence = 0.0
    class_counts = {}
    anomaly_count = 0  # å¼‚å¸¸æ£€æµ‹è®¡æ•°
    
    for det in pred:
        if len(det):
            # ä½¿ç”¨æ­£ç¡®çš„ç¼©æ”¾å‡½æ•°
            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], original_shape).round()
            
            # å¦‚æœå›¾ç‰‡è¢«æ”¾å¤§ï¼Œæ£€æµ‹æ¡†åæ ‡ä¹Ÿéœ€è¦ç›¸åº”æ”¾å¤§
            if scale_factor != 1.0:
                det[:, :4] *= scale_factor
                det[:, :4] = det[:, :4].round()
                
            detection_count += len(det)
            for *xyxy, conf, cls in reversed(det):
                if conf < ANOMALY_CONF_THRES:
                    # æœªçŸ¥äº¤é€šæ ‡å¿—ï¼ˆå¼‚å¸¸ï¼‰
                    class_name = 'Unknown Sign'
                    unique_classes.add(class_name)
                    total_confidence += conf.item()
                    label = f'Unknown Sign {conf:.2f}'
                    annotator.box_label(xyxy, label, color=(255, 0, 0))  # çº¢è‰²æ¡†
                    anomaly_count += 1
                else:
                    # å·²çŸ¥äº¤é€šæ ‡å¿—
                    c = int(cls)
                    class_name = names[c]
                    unique_classes.add(class_name)
                    total_confidence += conf.item()
                    label = f'{class_name} {conf:.2f}'
                    annotator.box_label(xyxy, label, color=colors(c, True))
                
                # æ›´æ–°ç±»åˆ«è®¡æ•°
                if class_name not in class_counts:
                    class_counts[class_name] = 0
                class_counts[class_name] += 1

    output_path = os.path.join(RESULT_FOLDER, file.filename)
    cv2.imwrite(output_path, annotator.result())

    # å‡†å¤‡æ£€æµ‹è¯¦æƒ…åˆ—è¡¨
    detections = []
    for class_name, count in class_counts.items():
        detections.append({
            'name': class_name,
            'count': count,
            'percentage': (count / detection_count * 100) if detection_count > 0 else 0.0
        })
    
    # æŒ‰æ£€æµ‹æ•°é‡æ’åº
    detections.sort(key=lambda x: x['count'], reverse=True)
    
    unique_classes_count = len(unique_classes)
    avg_confidence = (total_confidence / detection_count * 100) if detection_count > 0 else 0.0
    
    # è¿”å›ç»“æœé¡µé¢ï¼Œæ˜¾ç¤ºå¤„ç†åçš„å›¾ç‰‡å’Œç»Ÿè®¡ä¿¡æ¯
    return render_template('result.html', 
                         img_path=file.filename,
                         detection_count=detection_count,
                         unique_classes_count=unique_classes_count,
                         avg_confidence=avg_confidence,
                         detections=detections,
                         anomaly_count=anomaly_count,
                         inference_time=inference_time,
                         class_counts=class_counts,
                         conf_thres=conf_thres,
                         iou_thres=iou_thres)

@app.route('/predict_video', methods=['POST'])
def predict_video():
    file = request.files['video']
    if not file or not file.filename.lower().endswith(('.mp4', '.avi', '.mov', '.wmv')):
        return "è¯·ä¸Šä¼ æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶ï¼", 400
    
    # è·å–æ£€æµ‹å‚æ•°
    conf_thres = float(request.form.get('conf_thres', 0.25))
    iou_thres = float(request.form.get('iou_thres', 0.45))
    
    # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
    input_path = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(input_path)
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        return "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼", 400
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # åˆ›å»ºè§†é¢‘ç¼–å†™å™¨
    output_path = os.path.join(RESULT_FOLDER, file.filename)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # ä½¿ç”¨mp4æ ¼å¼
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
    detection_count = 0
    unique_classes = set()
    total_confidence = 0.0
    frame_detections = []
    anomaly_count = 0  # å¼‚å¸¸æ£€æµ‹è®¡æ•°
    class_counts = {}
    
    # å¼€å§‹è®¡æ—¶
    start_time = time.time()
    processed_frames = 0
    
    # é€å¸§å¤„ç†
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        processed_frames += 1
        
        # é¢„å¤„ç†
        img = letterbox(frame, 640, stride=stride)[0]
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
        img = torch.from_numpy(img.copy()).to(DEVICE).float() / 255.0
        img = img.unsqueeze(0)
        
        # æ¨ç†
        with torch.no_grad():
            pred = model(img, augment=True)[0]
            pred = non_max_suppression(pred, conf_thres=conf_thres, iou_thres=iou_thres)
        
        # åŠ¨æ€è®¡ç®—çº¿æ¡å®½åº¦ï¼Œæ ¹æ®å›¾ç‰‡å¤§å°è°ƒæ•´
        min_dim = min(frame.shape[0], frame.shape[1])
        line_width = max(1, int(min_dim / 300))  # æ¯300åƒç´ å¯¹åº”1ä¸ªåƒç´ å®½åº¦ï¼Œæœ€å°ä¸º1
        line_width = min(line_width, 4)  # æœ€å¤§å®½åº¦ä¸º4
        
        # ç”»æ£€æµ‹æ¡†
        annotator = Annotator(frame, line_width=line_width, example=str(names))
        
        # å¼‚å¸¸æ£€æµ‹è®¾ç½®ï¼šç½®ä¿¡åº¦é˜ˆå€¼
        ANOMALY_CONF_THRES = 0.5  # ä½äºæ­¤é˜ˆå€¼çš„æ£€æµ‹ç»“æœè§†ä¸ºå¼‚å¸¸
        
        frame_det_count = 0
        for det in pred:
            if len(det):
                # ä½¿ç”¨æ­£ç¡®çš„ç¼©æ”¾å‡½æ•°
                det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], frame.shape).round()
                frame_det_count += len(det)
                detection_count += len(det)
                for *xyxy, conf, cls in reversed(det):
                    if conf < ANOMALY_CONF_THRES:
                        # æœªçŸ¥äº¤é€šæ ‡å¿—ï¼ˆå¼‚å¸¸ï¼‰
                        class_name = 'Unknown Sign'
                        unique_classes.add(class_name)
                        total_confidence += conf.item()
                        label = f'Unknown Sign {conf:.2f}'
                        annotator.box_label(xyxy, label, color=(255, 0, 0))  # çº¢è‰²æ¡†
                        anomaly_count += 1
                    else:
                        # å·²çŸ¥äº¤é€šæ ‡å¿—
                        c = int(cls)
                        class_name = names[c]
                        unique_classes.add(class_name)
                        total_confidence += conf.item()
                        label = f'{class_name} {conf:.2f}'
                        annotator.box_label(xyxy, label, color=colors(c, True))
                    
                    # æ›´æ–°ç±»åˆ«è®¡æ•°
                    if class_name not in class_counts:
                        class_counts[class_name] = 0
                    class_counts[class_name] += 1
        
        # è®¡ç®—å®æ—¶FPS
        current_time = time.time()
        elapsed_time = current_time - start_time
        realtime_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
        
        # åœ¨è§†é¢‘ä¸Šæ˜¾ç¤ºFPSå’Œæ£€æµ‹æ•°é‡
        cv2.putText(frame, f'FPS: {realtime_fps:.1f}', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f'Detections: {frame_det_count}', (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # å†™å…¥å¤„ç†åçš„å¸§
        out.write(annotator.result())
        
        # è®°å½•æ¯å¸§æ£€æµ‹æ•°é‡
        frame_detections.append(frame_det_count)
    
    # é‡Šæ”¾èµ„æº
    cap.release()
    out.release()
    
    # è®¡ç®—æ€»å¤„ç†æ—¶é—´
    total_time = time.time() - start_time
    avg_fps = processed_frames / total_time if total_time > 0 else 0
    
    unique_classes_count = len(unique_classes)
    avg_confidence = (total_confidence / detection_count * 100) if detection_count > 0 else 0.0
    
    # å‡†å¤‡æ£€æµ‹è¯¦æƒ…åˆ—è¡¨
    detections = []
    for class_name, count in class_counts.items():
        detections.append({
            'name': class_name,
            'count': count,
            'percentage': (count / detection_count * 100) if detection_count > 0 else 0.0
        })
    
    # æŒ‰æ£€æµ‹æ•°é‡æ’åº
    detections.sort(key=lambda x: x['count'], reverse=True)
    
    # è¿”å›ç»“æœé¡µé¢ï¼Œæ˜¾ç¤ºå¤„ç†åçš„è§†é¢‘å’Œç»Ÿè®¡ä¿¡æ¯
    return render_template('result.html', 
                         video_path=file.filename,
                         detection_count=detection_count,
                         unique_classes_count=unique_classes_count,
                         avg_confidence=avg_confidence,
                         anomaly_count=anomaly_count,
                         avg_fps=avg_fps,
                         total_time=total_time,
                         detections=detections,
                         class_counts=class_counts)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)